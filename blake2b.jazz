// TODO: sigma
u64[192] sigma = { 
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ,
    14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 ,
    11, 8, 12, 0, 5, 2, 15, 13, 10, 14, 3, 6, 7, 1, 9, 4 ,
    7, 9, 3, 1, 13, 12, 11, 14, 2, 6, 5, 10, 4, 0, 15, 8 ,
    9, 0, 5, 7, 2, 4, 10, 15, 14, 1, 11, 12, 6, 8, 3, 13 ,
    2, 12, 6, 10, 0, 11, 8, 3, 4, 13, 7, 5, 15, 14, 1, 9 ,
    12, 5, 1, 15, 14, 13, 4, 10, 0, 7, 6, 3, 9, 2, 8, 11 ,
    13, 11, 7, 14, 12, 1, 3, 9, 5, 0, 15, 4, 8, 6, 2, 10 ,
    6, 15, 14, 9, 11, 3, 0, 8, 12, 2, 13, 7, 1, 4, 10, 5 ,
    10, 2, 8, 4, 7, 6, 1, 5, 15, 11, 9, 14, 3, 12, 13, 0 ,
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ,
    14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3 
};

// TODO: blake2b_iv
u64[8] blake2b_iv = { 0x6A09E667F3BCC908, 0xBB67AE8584CAA73B,
                      0x3C6EF372FE94F82B, 0xA54FF53A5F1D36F1,
                      0x510E527FADE682D1, 0x9B05688C2B3E6C1F,
                      0x1F83D9ABFB41BD6B, 0x5BE0CD19137E2179 };

inline fn G(stack u64[16] v, inline int a b c d, reg u64 x y) -> stack u64[16] {
  reg u64 v_a, v_b, v_c, v_d;

  // v[a] = v[a] + v[b] + x;
  v_b = v[b];
  v[a] += v_b;
  v[a] += x;
  
  // v[d] = ROTR64(v[d] ^ v[a], 32);
  v_a = v[a];
  v[d] ^= v_a;
  v_d = v[d];
  _, _, v_d = #ROR_64(v_d, 32);
  v[d] = v_d;

  // v[c] = v[c] + v[d];
  v_d = v[d];
  v[c] += v_d;

  // v[b] = ROTR64(v[b] ^ v[c], 24);
  v_c = v[c];
  v[b] ^= v_c;
  v_b = v[b];
  _, _, v_b = #ROR_64(v_b, 24);
  v[b] = v_b;

  // v[a] = v[a] + v[b] + y;
  v_b = v[b];
  v[a] += v_b;
  v[a] += y;

  // v[d] = ROTR64(v[d] ^ v[a], 16);
  v_a = v[a];
  v[d] ^= v_a;
  v_d = v[d];
  _, _, v_d = #ROR_64(v_d, 16);
  v[d] = v_d;

  // v[c] = v[c] + v[d];
  v_d = v[d];
  v[c] += v_d;

  // v[b] = ROTR64(v[b] ^ v[c], 63);
  v_c = v[c];
  v[b] ^= v_c;
  v_b = v[b];
  _, _, v_b = #ROR_64(v_b, 63);
  v[b] = v_b;

  return v;
}

inline fn blake2b_compress(stack u8[128] b, stack u64[8] h, stack u64[2] t, reg u8 last) -> stack u64[8] {
  stack u64[16] v, m;

  reg u64 t0, t1;
  reg u64 v_temp;
  reg u64 m1;
  reg u64 m2;

  reg u64 m_idx_1, m_idx_2;

  t0 = t[0];
  t1 = t[1];

  inline int i; // TODO: needed?

  for i = 0 to 8 {
    v[i] = h[i];
    v[i + 8] = blake2b_iv[i];
  }

  for i = 0 to 16 {
    m[i] = b.[u64 (8 * i)];
  }

  v[12] ^= t0;
  v[13] ^= t1;

  if (last == 1) {
    // flip all bits
    v[14] ^= 0xFFFFFFFFFFFFFFFF;
  }

  // skip the endianness
  for i = 0 to 12 {
    m_idx_1 = sigma[i * 16 + 0];
    m_idx_2 = sigma[i * 16 + 1];
    v = G(v, 0, 4, 8, 12, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 2];
    m_idx_2 = sigma[i * 16 + 3];
    v = G(v, 1, 5,  9, 13, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 4];
    m_idx_2 = sigma[i * 16 + 5];
    v = G(v, 2, 6, 10, 14, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 6];
    m_idx_2 = sigma[i * 16 + 7];
    v = G(v, 3, 7, 11, 15, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 8];
    m_idx_2 = sigma[i * 16 + 9];
    v = G(v, 0, 5, 10, 15, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 10];
    m_idx_2 = sigma[i * 16 + 11];
    v = G(v, 1, 6, 11, 12, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 12];
    m_idx_2 = sigma[i * 16 + 13];
    v = G(v, 2, 7,  8, 13, m[(int)m_idx_1], m[(int)m_idx_2]);
    m_idx_1 = sigma[i * 16 + 14];
    m_idx_2 = sigma[i * 16 + 15];
    v = G(v, 3, 4,  9, 14, m[(int)m_idx_1], m[(int)m_idx_2]);
  }

  for i = 0 to 8 {
    v_temp = v[i + 8];
    v[i] ^= v_temp;
    v_temp = v[i];
    h[i] ^= v_temp;
  }

  return h;
}

inline fn blake2b_update(
  stack u8[128] b, 
  reg u64 c, 
  stack u64[8] h, 
  stack u64[2] t, 
  reg u64 in,
  reg u64 inlen
) -> stack u8[128], reg u64, stack u64[8], reg u64[2] {
  reg u64 i;

  i = 0;
  while (i < inlen) {
    if (c == 128) {
      t[0] += c;
      if (t[0] < c) {
        t[1] += 1;
      }
      h = blake2b_compress(b, h, t, 0);
      c = 0;
    }
    b[(int)c] = (u8)[in + i];

    c += 1;
    i += 1;
  }
  return b, c, h, t;
}

inline fn blake2b_init(
  reg u64 outlen, 
  reg u64 key, 
  reg u64 keylen
) -> stack u8[128], reg u64, stack u64[8], stack u64[2] {
  stack u8[128] b;
  reg u64 c;
  stack u64[8] h;
  stack u64[2] t;

  reg u64 h0_scratch;
  reg u64 buf_idx;

  inline int i;

  // reject bad params in main fn

  // initialization vector
  for i = 0 to 8 {
    h[i] = blake2b_iv[i];
  }

  h0_scratch = keylen;
  h0_scratch <<= 8;
  h0_scratch ^= 0x01010000;
  h0_scratch ^= outlen;
  h[0] ^= h0_scratch;

  t[0] = 0;
  t[1] = 0;
  c = 0;

  buf_idx = keylen;
  while (buf_idx < 128) {
    b[(int) buf_idx] = 0;
    buf_idx += 1;
  }

  if (keylen > 0) {
    b, c, h, t = blake2b_update(b, c, h, t, key, keylen);
    c = 128;
  }

  return b, c, h, t;
}

inline fn blake2b_final(
  stack u8[128] b, 
  reg u64 c, 
  stack u64[8] h, 
  stack u64[2] t, 
  reg u64 out, 
  reg u64 outlen
) {
  
  reg u64 i, h_idx, h_lhs, h_rhs;

  t[0] += c;
  if (t[0] < c) {
    t[1] += 1;
  }

  while (c < 128) {
    b[(int)c] = 0;
    c += 1;
  }

  h = blake2b_compress(b, h, t, 1);

  i = 0;
  while (i < outlen) {
    h_idx = i;
    _, _, h_idx = #ROR(h_idx, 3);

    h_rhs = i;
    h_rhs &= 7;
    h_rhs *= 8;

    h_lhs = h[(int) h_idx];
    _, _, h_lhs = #ROR(h_lhs, h_rhs);
    h_lhs &= 0xFF;

    // TODO: need to ensure we're reading by u8 here, perhaps
    // jasmin has ways of indexing different memory sizes
    [out + i] = h_lhs;
    i += 1;
  }
}

export fn blake2b_jazz(
  reg u64 out, 
  reg u64 outlen,
  reg u64 key,
  reg u64 keylen,
  reg u64 in, 
  reg u64 inlen
) -> reg u64 {
  stack u8[128] b;
  stack u64[8] h;
  stack u64[2] t;

  reg u64 r;
  reg u64 c;

  r = 0;
  if (outlen == 0) {
    r = -1;
  } else if (outlen > 64) { 
    r = -1;
  } else if (keylen > 64) { 
    r = -1;
  } else { 
    b, c, h, t = blake2b_init(outlen, key, keylen);
    b, c, h, t = blake2b_update(b, c, h, t, in, inlen);
    blake2b_final(b, c, h, t, out, outlen);
  }
  return r;
}
